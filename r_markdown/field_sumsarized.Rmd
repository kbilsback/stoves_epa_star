---
title: "field_sumsarized"
author: "ricardo_piedrahita"
date: "8/10/2017"
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
---

```{r library, message=FALSE, warning=FALSE, echo=FALSE}
  library(tidyverse)
  library(knitr)
  library(lubridate)
  library(dplyr)
  library(plyr)
  library(magrittr)
  library(data.table)
  library(ggplot2)
  library(ggpubr)
  library(plotly)
```

```{r global_options, include=FALSE}
  knitr::opts_chunk$set(fig.path='figures/', warning=FALSE, message=FALSE, cache=FALSE)
```

```{r functions}
  source("../r_scripts/functions.R")
  source("../r_scripts/plots.R")
  source("../r_scripts/filter_sum_data.R")
```

# Load data

* Time stamps are fixed in the data importing step

```{r load_data}
  field_sumsarized_events <- readRDS("../r_files/field_sumsarized_events.RDS") #Data analyzed by Geocene, directly giving events
  field_sumsarized_csvdurations <- readRDS("../r_files/field_sumsarized_durations.RDS") #CSVs used by Geocene to get events.  These are needed so that we know the sampling time duration for average usage stats.
  field_sumsarized_timeseries <- readRDS("../r_files/field_sumsarized_timeseries.RDS") #Import data that was analyzed with the web-based sumsarizer tool.
```

* metadata

```{r load_meta}
  field_test_times <- readRDS("../r_files/field_test_times.RDS")
  field_samples <- readRDS("../r_files/field_samples.RDS")
  field_temp_meta <- readRDS("../r_files/field_temp_meta.RDS")
  field_notes <- readRDS("../r_files/field_notes.RDS")
  honduras_behavior <-readRDS("../r_files/honduras_behavior.RDS") #Import self-reported data from Honduras.
```

* Define variables for coding stoves and for filtering out data.  Also set some constants for the stove event analysis

```{r define_variables}
  stove_codes <- data.frame(stove = as.factor(c("Metal jiko","Traditional ceramic","Metal jiko ceramic","Uga","Traditional ceramic metal clad","Kerosene","Tire Rim","Traditional chimney","KNG","CLH","CLC","IBP","CLH1","Other","PB-OK","PB-IK", "PB-IK-E","LPG","TSF","PB-OK Biomass mobile","RS-IK","chimney","traditional","chimney2")),
                            stove_descriptions = as.factor(c("Jiko-style", "Jiko-style", "Jiko-style", "Jiko-style","Jiko-style","Kerosene", "Tire rim","Traditional chimney","Kang","Coal heating with chimney","Coal cooking with chimney", "Biomass pellet with chimney", "Coal heating with chimney","Other","Chulha", "Chulha", "Chulha", "LPG", "Three stone fire", "Ceramic rocket", "Rocket","Chimney","Three stone fire","Chimney")))
  
  cooking_group <- 10 # 30 minute window for grouping events together.
  cooking_duration_minimum <- 10
  
  
    # Remove data from files selected as bad (they match the following strings: 0_0_3_P54637_IndiaDMYminave
  bad_files <- paste(c("^0_0_3_P83601_IndiaDMYminave","|0_0_3_P46673_Indiaminaves","|0_0_3_P54588_Indiaminaves"
                 ,"|0_0_3_P46673_Indiaminaves","|0_0_0_P57934_Indiaminaves","|0_0_0_P83591_IndiaDMYminaves"
                 ,"|0_0_0_P83601_Indiaminaves","|0_0_2_P57934_Indiaminaves","|0_0_2_P83591_Indiaminaves"
                 ,"|0_0_3_P54637_IndiaDMYminaves","|0_0_4_P46673_IndiaDMYminaves","|IN7_P54593_20160419_Indiaminaves"
                 ,"|IN8_P83591_20160419_Indiaminaves","|IN8_P83591_20160503_IndiaDMYMinAves",
                 "|IN10_P57934_20160427_Indiaminaves"
                 ,"|IN10_P57934_20160503_Indiaminaves","|IN11_P46673_20160420_Indiaminaves",
                 "|IN11_P46673_20160503_IndiaDMYMinAves"
                 ,"|IN12_P54637_20160503_IndiaDMYMinAves","|INXX_P53257_20160430_Indiaminaves$"),collapse="")
  

```

# Tidy

* add household id information, get metadata from metadata file and from file names, depending on country
```{r parse_add_metadata}
#Use the same filtering on both the data set prepared by Geocene that gave events, and the data output by Sumsarizer that gives a time series.
field_sumsarized_events_all<-filter_sum_data(field_sumsarized_events,field_temp_meta,bad_files)

field_sumsarized_events_all_durations<-filter_sum_data(field_sumsarized_csvdurations,field_temp_meta,bad_files)

#Import thermocouple data output from Sumsarizer.
field_sumsarized_timeseries_batch2 <-filter_sum_data(field_sumsarized_timeseries,field_temp_meta,bad_files)

#Time series version needs additional filtering and massaging to form in cooking events.

```

#Form cooking events from raw sumsarizer output don't need it for the event data generated by Danny Wilson
* Group distinct cooking events together.  If they are within cooking_group minutes of each other.
* Only need this for data that went through the web-based sumsarizer, where events are not made automatically.
```{r group_cooking_events}
# 
# # start counting up for cooking events.  Add columns for start and stop times of cooking events, and keep the hhid, loggerid, stove type, field site.  Keep only cooking event time points.  Need a case for start (if i = 1), if data point is within 30minutes of the last one, if data point is greater than 30 minutes from the last one.

# #Initialize the cooking_events frame.
 cooking_events_timeseries <- data.frame(start_time=as.POSIXct(character()),end_time=as.POSIXct(character()), field_site=factor(),  hh_id=factor(), logger_id=factor(),stove=factor(), logging_start_time=as.POSIXct(character()), logging_end_time=as.POSIXct(character()),file_indices = as.numeric(),events_per_file = as.numeric())

 #for each SUM data file
 for (i in 1:max(field_sumsarized_timeseries_batch2$file_indices)) {
   #Grab data from file i, and keep only the entries that are marked as cooking
   temp <- dplyr::filter(field_sumsarized_timeseries_batch2,file_indices == i) %>%
     dplyr::filter(state == TRUE)

   difftime <- as.numeric(diff(temp$datetime)) #Time between identified cooking samples, in minutes
   breakstart <- c(0,which((difftime>cooking_group) == TRUE))+1 #Start of a cooking event
   breakend <- c(which((difftime>cooking_group) == TRUE),if (tail(temp$state,n=1) == TRUE){dim(temp)[1]}) #End of cooking event. Last part is in case the time series ends while still cooking...need to account for that.
   #Add cooking events to the cooking_events_timeseries data frame.
   cooking_events_timeseries <- rbind(cooking_events_timeseries,data.frame(start_time=as.POSIXct(temp$datetime[breakstart]),end_time=as.POSIXct(temp$datetime[breakend]), field_site=as.factor(temp$field_site[breakstart]), hh_id=as.factor(temp$hh_id[breakstart]), logger_id=factor(temp$logger_id[breakstart]),stove=factor(temp$stove[breakstart]), logging_start_time=as.POSIXct(temp$datetime[1]),logging_end_time = as.POSIXct(max(temp$datetime)),file_indices = temp$file_indices[breakstart], events_per_file = length(breakstart)*breakstart/breakstart,filename = temp$filename[breakstart]))

 }

 cooking_events_timeseries <- dplyr::left_join(cooking_events_timeseries,dplyr::select(stove_codes,stove,stove_descriptions),by = "stove") %>%
        dplyr::mutate(units = "degrees Celsius") %>% #Define units as degrees C
        dplyr::mutate(duration_minutes = as.numeric(difftime(end_time,start_time,units = "mins"))) %>%
        dplyr::mutate(logging_duration_days = as.numeric(difftime(logging_end_time, logging_start_time,units = "days"))) %>%
        dplyr::filter(duration_minutes>cooking_duration_minimum) %>%
        dplyr::mutate(events_per_day = events_per_file/logging_duration_days) %>%
        dplyr::mutate(minutes_per_day = logging_duration_days) %>%
        dplyr::mutate(hour_of_day = ((hour(end_time) + minute(end_time)/60) + (hour(start_time) + minute(start_time)/60))/2)

#Data summaries
 simpledatasummary <- summarise_each(field_sumsarized_events_all,funs(n_distinct(.)))

 grouped_summary <- cooking_events_timeseries %>% dplyr::group_by(field_site,stove_descriptions) %>%
    dplyr::summarize(mean=mean(duration_minutes, na.rm = TRUE), median=median(duration_minutes, na.rm = TRUE),sd=sd(duration_minutes, na.rm = TRUE),n=n())

 #Get a single row from each file so we can look at the stats calculated previously.
  hh_file_average_summary <- dplyr::filter(cooking_events_timeseries,!duplicated(filename))
```

* Clean up cooking events.  Removing events with a single sample that indicates cooking, more than 30 minutes from other events.
* Summary stats

```{r clean_cooking_events}

#Combine cooking events from the SUMsarized data set by Danny, with the ones from the thermocouples.
all_cooking_events <- rbind(field_sumsarized_events_all,cooking_events_timeseries)

#Remove data from SUMs that were secondary measurements (this happened in Honduras during piloting).  To do this, remove data from chimney2 - these were duplicate placements.

#Clean up the event data, define units, set up some grouping variables
all_cooking_events <- 
        dplyr::left_join(all_cooking_events,
                                        dplyr::select(stove_codes,stove,stove_descriptions),by = "stove") %>%
        dplyr::mutate(units = "degrees Celsius") %>% #Define units as degrees C
        dplyr::filter(logging_duration_days>1) %>% #Remove data from files shorter than 1 day.  Including these would bias the results as they were most likely from field emissions tests.
        dplyr::filter(duration_minutes>cooking_duration_minimum) %>%
        dplyr::filter(stove>cooking_duration_minimum) %>%
        dplyr::group_by(hh_id,stove) %>%   #group_by is handy.
        dplyr::mutate(events_per_hhid_stove = n()) %>%
        dplyr::mutate(minutes_per_hhid_stove = sum(duration_minutes)) %>%
        dplyr::mutate(hour_of_day = hour(start_time) + minute(start_time)/60) %>%
        dplyr::arrange(hh_id) 

#Summarize use by household/deployment/stove for plotting average use.
events_summary <- dplyr::filter(all_cooking_events,!duplicated(filename)) %>%
        dplyr::group_by(hh_id,stove) %>%   
        dplyr::mutate(days_logged_per_hhid_stove = sum(logging_duration_days))   %>%
        dplyr::mutate(events_per_day = events_per_hhid_stove/days_logged_per_hhid_stove) %>%
        dplyr::mutate(minutes_per_day_stove_hhid = minutes_per_hhid_stove/days_logged_per_hhid_stove) %>%
        dplyr::select(-event_num,-start_time,-duration_minutes,-max_temp,-min_temp) %>%
        dplyr::distinct(events_per_day, .keep_all = TRUE)


```


* set timezones based on field site

```{r fix_timezones}
  all_cooking_events <- dplyr::mutate(all_cooking_events,
                                         datetime = lubridate::force_tz(datetime,
                                                                        tzone = "Asia/Calcutta"))
```


* Plot usage rates (uses/day) by stove type, and region
```{r plot_stove_usage}


give.n <- function(x){
   return(c(y = 0, label = length(x)))
}


#To make box and whiskers quantiles rather than IQRs.
f <- function(x) {
  r <- quantile(x, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

#Plot average uses per day
gg <- ggplot(events_summary, aes(x=stove_descriptions, y = events_per_day)) + 
  stat_summary(fun.data = f, geom="boxplot") + 
  facet_grid(~field_site,scales = "free", space = "free") + 
  labs(y="Average uses/day",x="") + 
  stat_summary(fun.data = give.n, geom = "text") +
  stat_summary(fun.data = give.sum, geom = "text") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) 
  # geom_text(data = events_summary %>% 
  #                        group_by(stove_descriptions) %>% 
  #                        summarise(ndays = list(sum(days_logged_per_hhid_stove))) %>% 
  #                        tidyr::unnest(), 
  #              aes(x = factor(stove_descriptions), y = -.5, label = paste("days=",ndays)), 
  #              nudge_x = .5)
gg



#Plot average time used per day
gg1 <- ggplot(events_summary, aes(x=stove_descriptions, y = minutes_per_day_stove_hhid)) + 
  stat_summary(fun.data = f, geom="boxplot") + 
  facet_grid(~field_site,scales = "free", space = "free") + 
  labs(y="Average minutes used/day",x="") + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
gg1

p1 +
  geom_point(aes(color=Home.Value, shape = region)) +
  geom_smooth()

p <- ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point()
p + facet_wrap(~cyl)




```

# QC

## flags from notes

* extract notes

```{r get_notes}
  field_notes <- dplyr::filter(field_notes, grepl("sumsarized|all", field_notes$inst) == TRUE)
```

* apply flags: `bad` preceeds `maybe` preceeds `good`

```{r flags}
  flags <- dplyr::select(field_notes, hh_id, qc) %>%
           dplyr::group_by(hh_id) %>%
           dplyr::arrange(qc) %>%
           dplyr::summarise(qc = first(qc))
```

* merge flags with data

```{r merge_flags}
  # fix warning
  all_cooking_events <- dplyr::left_join(all_cooking_events, flags, by = "hh_id") %>%
                           dplyr::mutate(qc = as.factor(ifelse(is.na(qc), "ok", as.character(qc)))) %>%
                           dplyr::mutate(qc = forcats::lvls_expand(qc, c("bad", "maybe", "ok")))
```

## additional bad tests

```{r bad_tests_2}
  all_cooking_events$qc[all_cooking_events$hh_id == "IN4"] <- "maybe"
```

## Filter only test

```{r get_times}
  field_times <- dplyr::filter(field_test_times, var == "sample_start" | var == "sample_end") %>%
                 tidyr::spread(var, value) %>%
                 dplyr::rename(start = sample_start, end = sample_end)
```

```{r filter_tests}
  # currently missing all data from emissions households
  #field_sumsarized_events <- filter_times(field_times, field_sumsarized_events_all)
```

# Plots

## all data

```{r plot_all_temp_data, fig.width=12, fig.height=20}
  field_timeseries_plot(field_sumsarized_events_all, "stove_temp")
```

## data summary

```{r boxplot_temp, fig.width=12, fig.height=4}
  field_boxplot(field_sumsarized_events_all, "stove_temp")
```

## test data only

```{r plot_test_temp, fig.width=12, fig.height=10}
  # missing all test day data
  #field_timeseries_plot(field_temp_merged, "temp")
```

# Summary

Temperature was measured for `r length(unique(field_sumsarized_events_all$hh_id))` experiments between `r min(field_sumsarized_events_all$date, na.rm = TRUE)` and `r max(field_sumsarized_events_all$date, na.rm = TRUE)`. There is no temperature data for tests: `r setdiff(as.character(field_samples$hh_id), as.character(field_sumsarized_events_all$hh_id))`.

Temperature data is expected to be missing for: no tests.

## Save files

* put data into long format

```{r long_data_conversion}
  field_sumsarized_events_all <- dplyr::select(field_sumsarized_events_all, field_site, hh_id, date, time, datetime, stove_temp, units, qc) %>%
                           tidyr::gather("var", "val", 6)

  #field_sumsarized_events <- dplyr::select(field_sumsarized_events, hh_id, date, time, datetime, stove_temp, units, qc, field_site) %>%
                       #tidyr::gather("var", "val", 5:8)
```

* save data

```{r save_data}
  saveRDS(field_sumsarized_events_all, file = "../r_files/field_sumsarized_events_all.RDS")
  #saveRDS(field_sumsarized_events, file = "../r_files/field_sumsarized_events.RDS")
```


